# Configuracion del servidor de Showdown
server:
  local:
    host: "localhost"
    port: 8000
  showdown:
    host: "sim.smogon.com"
    port: 8000

# Credenciales (rellenar antes de jugar en el ladder)
credentials:
  username: ""
  password: ""

# Configuracion del entrenamiento
training:
  mode: "self_play"          # self_play | ladder | hybrid
  total_timesteps: 1_000_000
  n_envs: 4                  # partidas en paralelo durante self-play
  save_freq: 50_000           # cada cuantos steps guardar el modelo
  log_dir: "logs/"
  model_dir: "models/"
  model_dir_heuristic: "models/vs_heuristic/"
  model_dir_self: "models/vs_self/"

# Hiperparametros del agente PPO
ppo:
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 128            # más estable que 64
  n_epochs: 15               # más pasadas de gradiente por rollout (era 10)
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.005            # menos exploración aleatoria (era 0.01)

# Formato de batalla
battle:
  format: "gen9randombattle"

# Reward shaping
reward:
  win: 1.0
  lose: -1.0
  faint_enemy: 0.5           # v3: más incentivo para ir al KO (era 0.35 en v2.1)
  own_faint: -0.05           # v3: menos miedo a morir → más agresividad
  hp_fraction_coef: 0.02     # recompensa por diferencia de HP al final
  switch_penalty: -0.02      # v3: penalización por cambiar innecesariamente
  boost_coef: 0.03           # v3: recompensa por ganar boosts ofensivos (Swords Dance, etc.)
